{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最小データ数の取得用関数\n",
    "最もサンプル数の少ないデータの数を取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_min_data_num(num_classes):\n",
    "    # init\n",
    "    dict_num = []\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        file_name = \"./data/\" + TRAIN_DATA_FILES[i] + '.csv'\n",
    "        data_set = pd.read_csv(file_name, header=None)\n",
    "        \n",
    "        num_data_set = len(data_set)\n",
    "        dict_num.append(num_data_set)\n",
    "        \n",
    "        print(TRAIN_DATA_FILES[i], num_data_set, sep=': ')\n",
    "\n",
    "    min_data_num = min(dict_num)\n",
    "    print('\\n')\n",
    "    print(\"min_data_num:\", min_data_num)\n",
    "    \n",
    "    return min_data_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross: 688\n",
      "dead: 4377\n",
      "left: 2590\n",
      "right: 1852\n",
      "straight: 3952\n",
      "threeway: 10048\n",
      "\n",
      "\n",
      "min_data_num: 688\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA_FILES = ['cross', 'dead', 'left', 'right', 'straight', 'threeway']\n",
    "# NUM_CLASSES = 6\n",
    "NUM_CLASSES = len(TRAIN_DATA_FILES)\n",
    "num_data_set = search_min_data_num(NUM_CLASSES)\n",
    "REPLACE_NAN = 0\n",
    "\n",
    "epochs = 120\n",
    "batch_size = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## チューニングパラメータ設定\n",
    "辞書内の数字を全通り試して最もスコアの高いものを選ぶことができる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param():\n",
    "    ret = {\n",
    "        'mid_lay1':[300, 600, 800, 900, 1000, 1100],\n",
    "        'mid_lay2':[300, 600, 800, 900, 1000, 1100],\n",
    "        'dropout1':[0.2, 0.3, 0.4, 0.5],\n",
    "        'dropout2':[0.2, 0.3, 0.4, 0.5]\n",
    "#        'optimizer':[\"adam\", \"adagrad\"]\n",
    "    }\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データ数の取得用関数  \n",
    "データ読み込み時、それぞれのラベルの学習データの内、最も数の少ないものに合わせる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_data_num(num_class):\n",
    "    # header = 列名\n",
    "    file_name = \"./data/\" + TRAIN_DATA_FILES[num_class] + '.csv'\n",
    "    data_set = pd.read_csv(file_name, header=None)\n",
    "\n",
    "    return data_set.sample(num_data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データ読み込み用関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data():\n",
    "    files = os.listdir('./data')\n",
    "    X = []\n",
    "    Y = []\n",
    "    all_data_set = []\n",
    "    labels = []\n",
    "\n",
    "\n",
    "    for i in range(NUM_CLASSES):\n",
    "        try:\n",
    "            data_set = adjust_data_num(i)\n",
    "            all_data_set.append(data_set)\n",
    "\n",
    "            # one_hot_vectorを作りラベルとして追加\n",
    "            tmp = np.zeros((num_data_set, NUM_CLASSES))\n",
    "            tmp[:, i] = 1\n",
    "            labels.append(tmp)\n",
    "        except pd.io.common.EmptyDataError:\n",
    "            print(\"ERROR: {} is empty\".format(file_name))\n",
    "\n",
    "    X = pd.concat(all_data_set)\n",
    "    # replace Nan with 'REPLACE_NAN'\n",
    "    X = X.fillna(REPLACE_NAN)\n",
    "    Y = np.concatenate(labels, axis=0)\n",
    "\n",
    "#    _, DIM_input_data = data_set.shape\n",
    "\n",
    "    X_train, X_validation_and_test, Y_train, Y_validation_and_test = train_test_split(X, Y,train_size=0.6, test_size=0.4)\n",
    "    X_validation, X_test, Y_validation, Y_test = train_test_split(X_validation_and_test, Y_validation_and_test, train_size=0.5, test_size=0.5)\n",
    "\n",
    "    return X_train, X_validation, X_test, Y_train, Y_validation, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## グラフプロット用関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_result(epochs, history):\n",
    "    plt.plot(range(1, epochs+1), history.history['acc'], label=\"training\")\n",
    "    plt.plot(range(1, epochs+1), history.history['val_acc'], label=\"validation\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワーク設計\n",
    "現在  \n",
    "input(726) -  \n",
    "<span>　</span>mid_lay1(dropout1) - mid_lay2(dropout2) -  \n",
    "<span>　　</span>output(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(activation=\"relu\", optimizer=\"adam\", mid_lay1=100, mid_lay2=100, dropout1=0.25, dropout2=0.25):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(mid_lay1, input_dim=726, activation=activation))\n",
    "    model.add(Dropout(dropout1))\n",
    "\n",
    "    model.add(Dense(mid_lay2, activation=activation))\n",
    "    model.add(Dropout(dropout2))\n",
    "\n",
    "    model.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### データ読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, X_test, Y_train, Y_validation, Y_test = split_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n",
      "285\n",
      "112\n",
      "ERROR: ./data/right.csv is empty\n",
      "3798\n",
      "696\n",
      "0.7665677549930991\n",
      "{'dropout1': 0.25, 'dropout2': 0.25, 'mid_lay1': 200, 'mid_lay2': 200}\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_187 (Dense)            (None, 200)               145400    \n",
      "_________________________________________________________________\n",
      "dropout_125 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dropout_126 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 6)                 1206      \n",
      "=================================================================\n",
      "Total params: 186,806\n",
      "Trainable params: 186,806\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Retrieve model and parameter into GridSearchCV\n",
    "model = KerasClassifier(build_fn=make_model, verbose=0)\n",
    "\n",
    "param_grid = param()\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "\n",
    "# Run grid search\n",
    "grid_result = grid.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best score and the optimized mode\n",
    "print (grid_result.best_score_)\n",
    "print (grid_result.best_params_)\n",
    "\n",
    "# Now see the optimized model\n",
    "mid_lay1 = grid_result.best_params_['mid_lay1']\n",
    "mid_lay2 = grid_result.best_params_['mid_lay2']\n",
    "dropout1 = grid_result.best_params_['dropout1']\n",
    "dropout2 = grid_result.best_params_['dropout2']\n",
    "\n",
    "model = make_model(mid_lay1=mid_lay1, mid_lay2=mid_lay2, dropout1=dropout1, dropout2=dropout2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
