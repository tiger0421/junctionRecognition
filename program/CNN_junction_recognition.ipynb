{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN_junction_recognition.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python2","display_name":"Python 2"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"qCNfLR3jJDc9","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from keras import backend as K\n","config = tf.ConfigProto()\n","config.gpu_options.allow_growth = True\n","config.gpu_options.visible_device_list=\"0\"\n","sess = tf.Session(config=config)\n","K.set_session(sess)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9zBG9Ug8Jm8X","colab_type":"code","colab":{}},"source":["from keras.models import Sequential, Model\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6edW7fH8KDSO","colab_type":"code","colab":{}},"source":["num_classes = 2\n","img_height, img_width = 64, 64\n","\n","def Mynet():\n","    model = Sequential()\n","    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(img_height, img_width, 3)))\n","    model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","    model.add(Dropout(0.25))\n","\n","    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n","    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","    model.add(Flatten())\n","    model.add(Dense(512, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(num_classes))\n","    model.add(Activation('softmax'))\n","\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2wNmW3W3KRZA","colab_type":"code","colab":{}},"source":["import keras"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WoGRlMZpLoFa","colab_type":"code","colab":{}},"source":["model = Mynet()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zkV3FYqxTEwm","colab_type":"text"},"source":["###各層のパラメータを学習するように設定"]},{"cell_type":"code","metadata":{"id":"Q26aGqbdQD-4","colab_type":"code","colab":{}},"source":["for layer in model.layers:\n","    layer.trainable = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ufcmXQES1FK","colab_type":"code","colab":{}},"source":["model.compile(loss='categorical_crossentropy',\n","                  optimizer=keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True),\n","                  metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hSMDC0FnTTr5","colab_type":"text"},"source":["###学習データ設定"]},{"cell_type":"code","metadata":{"id":"3NcCd-g9TQbO","colab_type":"code","colab":{}},"source":["from keras.preprocessing.image import ImageDataGenerator"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"85mD94WlTXNv","colab_type":"code","outputId":"ea7cb4c3-4353-4f0c-8642-f77561dadd29","executionInfo":{"status":"ok","timestamp":1573808613269,"user_tz":-540,"elapsed":1633,"user":{"displayName":"島田滉己","photoUrl":"","userId":"06467417530496067215"}},"colab":{"base_uri":"https://localhost:8080/","height":73}},"source":["train_datagen = ImageDataGenerator(\n","    rescale=1. / 255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    featurewise_center=True,\n","    featurewise_std_normalization=True,\n","    zca_whitening=True\n",")\n","\n","test_datagen = ImageDataGenerator(\n","    rescale=1. / 255,\n","    featurewise_center=True,\n","    featurewise_std_normalization=True,\n","    zca_whitening=True\n",")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python2.7/dist-packages/keras_preprocessing/image/image_data_generator.py:341: UserWarning: This ImageDataGenerator specifies `zca_whitening` which overrides setting of`featurewise_std_normalization`.\n","  warnings.warn('This ImageDataGenerator specifies '\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"wUbAxu0tTsUq","colab_type":"text"},"source":["###データ読み込み"]},{"cell_type":"code","metadata":{"id":"XGHBDRK1TaDe","colab_type":"code","outputId":"0bcfb980-63b7-4e58-9a00-d8492dc2c6ed","executionInfo":{"status":"error","timestamp":1573808684556,"user_tz":-540,"elapsed":1655,"user":{"displayName":"島田滉己","photoUrl":"","userId":"06467417530496067215"}},"colab":{"base_uri":"https://localhost:8080/","height":419}},"source":["train_generator = train_datagen.flow_from_directory(\n","    'Images/Train/',\n","    target_size=(img_height, img_width),\n","    batch_size=30,\n","    class_mode='categorical')\n","\n","validation_generator = test_datagen.flow_from_directory(\n","    'Images/Test/',\n","    target_size=(img_height, img_width),\n","    batch_size=1,\n","    class_mode='categorical')"],"execution_count":0,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mOSError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-21-2b05c7f857bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     class_mode='categorical')\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m validation_generator = test_datagen.flow_from_directory(\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras_preprocessing/image/image_data_generator.pyc\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         )\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras_preprocessing/image/directory_iterator.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory: 'Images/Train/'"]}]},{"cell_type":"markdown","metadata":{"id":"Pe-QmTUHT6G6","colab_type":"text"},"source":["###学習実行"]},{"cell_type":"code","metadata":{"id":"3-H4zdEGTrc4","colab_type":"code","colab":{}},"source":["history = model.fit_generator(\n","    train_generator,\n","    steps_per_epoch=50,\n","    epochs=100,\n","    validation_data=validation_generator,\n","    validation_steps=50\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WYwMMHZqUYxD","colab_type":"text"},"source":["###テスト"]},{"cell_type":"markdown","metadata":{"id":"dpVwQsYgUfTp","colab_type":"text"},"source":["###1枚画像読み込み"]},{"cell_type":"code","metadata":{"id":"HXWVGijhUZ8c","colab_type":"code","colab":{}},"source":["from PIL import Image\n","\n","file_path = 'Images/Test/class1/img.jpg'\n","img = Image.open(filepath).convert('RGB') ## Gray->L, RGB->RGB\n","img = img.resize((img_width, img_height))\n","x = np.array(img, dtype=np.float32)\n","x = x / 255."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_vatFGP8VCGa","colab_type":"code","colab":{}},"source":["pred = model.predict(x, batch_size=1, verbose=0)\n","score = np.max(pred)\n","pred_label = np.argmax(pred)"],"execution_count":0,"outputs":[]}]}